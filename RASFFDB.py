import streamlit as st
import pandas as pd
import sqlite3
import os
import requests
import base64
from io import BytesIO

st.set_page_config(layout="wide")

# Charger le token GitHub depuis les secrets Streamlit Cloud
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO_OWNER = "M00N69"
REPO_NAME = "RASFFDB"
FILE_PATH = "rasff_data.db"
GITHUB_API_URL = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"

DB_PATH = "rasff_data.db"

# Fonction pour cr√©er les colonnes manquantes
def add_missing_columns():
    with sqlite3.connect(DB_PATH) as conn:
        cursor = conn.cursor()
        cursor.execute("ALTER TABLE rasff_notifications ADD COLUMN year INTEGER")
        cursor.execute("ALTER TABLE rasff_notifications ADD COLUMN week INTEGER")
        cursor.execute("UPDATE rasff_notifications SET year = strftime('%Y', date)")
        cursor.execute("UPDATE rasff_notifications SET week = strftime('%W', date)")
        conn.commit()

# V√©rifier et ajouter les colonnes 'year' et 'week' si n√©cessaire
try:
    add_missing_columns()
except sqlite3.OperationalError:
    print("‚úÖ Les colonnes 'year' et 'week' existent d√©j√†.")

# Fonction pour t√©l√©charger le fichier depuis GitHub
def download_from_github():
    url = f"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/main/{FILE_PATH}"
    response = requests.get(url)
    with open(DB_PATH, "wb") as file:
        file.write(response.content)

# Fonction pour afficher les derni√®res entr√©es dans la base de donn√©es
def show_last_entries():
    st.write("üìä Derni√®res entr√©es dans la base de donn√©es :")
    with sqlite3.connect(DB_PATH) as conn:
        df = pd.read_sql("SELECT * FROM rasff_notifications ORDER BY date DESC LIMIT 5", conn)
    st.dataframe(df)

# Fonction pour mettre √† jour le fichier sur GitHub
def update_github():
    try:
        with open(DB_PATH, "rb") as file:
            content = file.read()
        encoded_content = base64.b64encode(content).decode()

        response = requests.get(GITHUB_API_URL, headers={
            "Authorization": f"Bearer {GITHUB_TOKEN}"
        })
        if response.status_code != 200:
            st.error("‚ùå Impossible de r√©cup√©rer les informations du fichier sur GitHub.")
            return

        response_data = response.json()
        sha = response_data.get("sha", None)

        if sha is None:
            st.error("‚ùå SHA non trouv√© pour le fichier sur GitHub.")
            return

        data = {
            "message": "Mise √† jour automatique de la base RASFF",
            "content": encoded_content,
            "sha": sha,
            "branch": "main"
        }

        response = requests.put(GITHUB_API_URL, json=data, headers={
            "Authorization": f"Bearer {GITHUB_TOKEN}"
        })

        if response.status_code in [200, 201]:
            st.success("‚úÖ Mise √† jour r√©ussie sur GitHub !")
        else:
            st.error(f"‚ùå √âchec de la mise √† jour sur GitHub : {response.json()}")
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la mise √† jour sur GitHub : {e}")

# Fonction pour v√©rifier la derni√®re semaine et ann√©e dans la base
def get_last_update_info():
    with sqlite3.connect(DB_PATH) as conn:
        query = "SELECT MAX(year), MAX(week) FROM rasff_notifications"
        result = conn.execute(query).fetchone()
    return result

# Fonction pour t√©l√©charger et ajouter les nouvelles donn√©es
def update_database():
    last_year, last_week = get_last_update_info()
    current_year = pd.Timestamp.now().year
    current_week = pd.Timestamp.now().week

    for year in range(last_year, current_year + 1):
        start_week = last_week + 1 if year == last_year else 1
        end_week = current_week if year == current_year else 52

        for week in range(start_week, end_week + 1):
            week_str = str(week).zfill(2)
            url = f"https://www.sirene-diffusion.fr/regia/000-rasff/{str(year)[-2:]}/rasff-{year}-{week_str}.xls"
            response = requests.get(url)

            if response.status_code == 200:
                st.write(f"üì• T√©l√©chargement r√©ussi pour {url}")
                try:
                    df = pd.read_excel(BytesIO(response.content))
                    st.write(f"‚úÖ Lecture du fichier Excel r√©ussie pour {year} - semaine {week_str}")
                    
                    if 'date' not in df.columns:
                        st.error(f"‚ùå Colonne 'date' manquante dans le fichier {year} - semaine {week_str}")
                        continue

                    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y %H:%M:%S', errors='coerce')
                    df['year'] = df['date'].dt.year
                    df['week'] = df['date'].dt.isocalendar().week

                    with sqlite3.connect(DB_PATH) as conn:
                        df.to_sql("rasff_notifications", conn, if_exists="append", index=False)
                    st.write(f"‚úÖ Donn√©es ins√©r√©es dans la base pour {year} - semaine {week_str}")
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la lecture du fichier Excel pour l'ann√©e {year}, semaine {week_str}: {e}")
            else:
                st.write(f"‚ùå Fichier non trouv√© pour l'ann√©e {year}, semaine {week_str}")
                continue

# Initialisation
if not os.path.exists(DB_PATH):
    download_from_github()

# Interface Streamlit
def main():
    st.title("üö® RASFF Alerts Dashboard")

    # Bouton pour mettre √† jour la base
    if st.button("üîÑ Mettre √† jour la base RASFF"):
        st.write("üì• T√©l√©chargement des nouvelles donn√©es...")
        update_database()
        show_last_entries()
        st.write("üì§ Synchronisation avec GitHub...")
        update_github()

    # R√©cup√©ration des donn√©es
    with sqlite3.connect(DB_PATH) as conn:
        df = pd.read_sql("SELECT * FROM rasff_notifications", conn)

    # Filtrage
    selected_country = st.sidebar.selectbox("Pays", ["Tous"] + sorted(df["notifying_country"].unique()))
    selected_year = st.sidebar.selectbox("Ann√©e", ["Tous"] + sorted(df["year"].unique(), reverse=True))
    selected_category = st.sidebar.selectbox("Cat√©gorie", ["Toutes"] + sorted(df["category"].unique()))

    # Application des filtres
    filtered_df = df.copy()
    if selected_country != "Tous":
        filtered_df = filtered_df[filtered_df["notifying_country"] == selected_country]
    if selected_year != "Tous":
        filtered_df = filtered_df[filtered_df["year"] == selected_year]
    if selected_category != "Toutes":
        filtered_df = filtered_df[filtered_df["category"] == selected_category]

    # Affichage
    st.write(f"## üìä {len(filtered_df)} alertes ({selected_year})")
    st.dataframe(filtered_df, height=600)

    # Graphiques
    st.write("## üåü R√©partition par pays")
    st.bar_chart(filtered_df["notifying_country"].value_counts().head(10))

if __name__ == "__main__":
    main()
