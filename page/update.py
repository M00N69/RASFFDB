import streamlit as st
import pandas as pd
import sqlite3
import requests
from io import BytesIO

# === CONFIGURATION ===
DB_PATH = "rasff_data.db"
YEAR = 2025  # Modifier selon l'ann√©e souhait√©e
WEEKS = list(range(1, 53))  # Semaines √† v√©rifier

# Mapping des colonnes XLS ‚Üí Base SQLite
COLUMN_MAPPING = {
    "date": "date_of_case",
    "reference": "reference",
    "notifying_country": "notification_from",
    "origin": "country_origin",
    "category": "product_category",
    "subject": "product",
    "hazards": "hazard_substance",
    "classification": "hazard_category",
}

# === FONCTIONS ===

def download_xls(year, week):
    """T√©l√©charge un fichier XLS √† partir de l'URL"""
    url = f"https://www.sirene-diffusion.fr/regia/000-rasff/{str(year)[2:]}/rasff-{year}-{str(week).zfill(2)}.xls"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return BytesIO(response.content)
    except requests.RequestException:
        return None

def extract_and_clean_xls(xls_data):
    """Lit et nettoie les donn√©es d'un fichier XLS"""
    df = pd.read_excel(xls_data)
    
    # Renommer les colonnes selon le mapping
    df = df.rename(columns=COLUMN_MAPPING)
    
    # Ajouter les colonnes manquantes avec valeur None
    for col in COLUMN_MAPPING.values():
        if col not in df.columns:
            df[col] = None
    
    # Convertir les dates
    df["date_of_case"] = pd.to_datetime(df["date_of_case"], errors="coerce").dt.strftime("%Y-%m-%d")
    
    return df[list(COLUMN_MAPPING.values())]  # Garder uniquement les colonnes utiles

def update_database(new_data):
    """Ins√®re les nouvelles donn√©es dans la base SQLite en √©vitant les doublons"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # V√©rifier les r√©f√©rences existantes pour √©viter les doublons
    existing_refs = pd.read_sql("SELECT reference FROM rasff_data", conn)["reference"].tolist()
    new_data = new_data[~new_data["reference"].isin(existing_refs)]
    
    # Ins√©rer les nouvelles donn√©es
    if not new_data.empty:
        new_data.to_sql("rasff_data", conn, if_exists="append", index=False)
        st.success(f"{len(new_data)} nouvelles alertes ajout√©es !")
    else:
        st.info("Aucune nouvelle alerte √† ajouter.")
    
    conn.close()
    return new_data

# === INTERFACE STREAMLIT ===
st.title("üîÑ Mise √† jour des alertes RASFF")

selected_weeks = st.multiselect("S√©lectionnez les semaines √† mettre √† jour :", WEEKS, default=WEEKS[:4])

if st.button("Mettre √† jour la base de donn√©es"):
    all_new_data = []
    
    for week in selected_weeks:
        st.write(f"üîç V√©rification de la semaine {week}...")
        xls_data = download_xls(YEAR, week)
        
        if xls_data:
            df = extract_and_clean_xls(xls_data)
            st.write(f"‚úÖ Donn√©es charg√©es pour la semaine {week} : {df.shape[0]} alertes.")
            all_new_data.append(df)
        else:
            st.warning(f"‚ùå Impossible de r√©cup√©rer les donn√©es pour la semaine {week}.")

    # Mettre √† jour la base de donn√©es si des donn√©es ont √©t√© r√©cup√©r√©es
    if all_new_data:
        full_data = pd.concat(all_new_data, ignore_index=True)
        inserted_data = update_database(full_data)
        st.dataframe(inserted_data)  # Afficher un aper√ßu des nouvelles donn√©es ins√©r√©es
